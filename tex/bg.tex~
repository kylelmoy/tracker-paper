\documentclass[main.tex]{subfiles}
\begin{document}
\section{Introduction}
The nematode \textit{Caenorhabditis elegans} is a popular organism for neural studies due to its simple structure (959 somatic cells) and known connectome (302 neurons and 8000 connections). Traditionally, this nematode is studied to model its behavioral output, observed through motion, given different experimental manipulations. Given that a nematode's behavior is only modulated by internal states (genetics) and external stimuli (such as presence or absence of food or touch-stimulus), manipulating these states and stimuli can lead to discovery about neural circuits' purposes and activity. For example, mutations can be applied to a worm to simulate human diseases like Alzeihmer's, Autism Spectrum Disorders and other neural-disruption diseases. The impact of such genetic manipulations can then be measured to infer linkages between genes, neurons and behavior. \textit{C. elegans} related research often aims to discover which neurons control behavior in the hope that findings can be generalized to aid in the development of a human brain activity map to better understand diseases caused by neural disruption.\\

A common practice in the \textit{C. elegans} Neuroscience research field is to quantify a worm's locomotory behavior using Computer Vision techniques. This interdisciplinary approach hopes to provide more precise measurement and description tools of \textit{C. elegans'} locomotory behavior to make inferences in the field of Neuroscience.\\
  %more uses

Specifically, our collaborator, Dr. Kim at Rosalind Franklin University of Medical Sciences, wishes to know which neurons affect the food related behavior of \textit{C. elegans}. In order to discover this, he proposes to quantify a wild-type worm's off-food behavior and find similarly behaving mutant worms when placed in an on-food environment. For our purposes, worm food is an \textit{E. coli} bacterial lawn spread on an agar plate assay. Knowing which worm(s) from a list of possible candidate mutants behave on-food as the wild-type (naturally occurring) off-food, will suggest to Dr. Kim which neurons are part of the food-related behavior neural circuit. Knowing how similarly these worms behave will infer the strength of certain neural paths over others under the food-presence condition. In order to observe and quantify the intricacies of \textit{C. elegans'} food related behavior, Dr. Kim needs a system to record, measure, quantify and model \textit{C. elegans} behavior through video and image processing. \\

\section{Background}
Due to the ineffectiveness of humans to observe and record worm activity with precision over either long or short time scales, it has become almost standard to record freely moving \textit{C. elegans} either one at a time or in a group. These videos are then processed after the fact, to segment the worm and provide intermediate representations of the worm's body (binary image, skeleton and sampled skeleton points). Features are then extracted from the intermediate representations and further mined for patterns to quantify phenotypes as in \cite{yemini2013} or to support hypotheses linking genetic manipulation to observed locomotory behavior.\\ %more examples, eventually

Some recording implementations (\cite{ramot2008, tsibidis2007}) focus on one area of the dish, negating the need to recenter the worm(s) under study. Quantitative methods developed for this type of system are used to track the centroid of multiple worms only in that area of the assay and do not require a motorized tracker. Other implementations (\cite{feng2004}) used either a motorized stage (usually when using a microscope providing this functionality) or a motorized X-Y translation stage upon which a camera is affixed. Moving the camera over the stage (containing the assay and thus animal under study) is preferred to minimize the possible effects of the mechanical motion on the nematode's locomotory behavior. \\

We wish to record one worm at a time and are interested in comparing his locomotory behavior off-food to candidate mutant worms on food. It has been suggested in \cite{} that wild-type \textit{C. elegans'} off-food behavior is remarkably different from an on-food environment. Worms under this condition can travel longer distances in more frenetic behavioral patterns (ie: fast with many turns), requiring a larger dish to give the nematode space to search for food without colliding with the edge of the dish. Other research groups use an \textit{E. coli} bacterial lawn (food) to restrict the area in which the animal will visit, and to minimize its maximal speed as explained in \cite{}. This highlights the importance of developing a system for which a minimal amount of parameters need to be tweaked for appropriate motorized tracking is minimal for any type of worm under any experimental condition. For this system to be useful to Dr. Kim, the motorized tracking parameters need to be generalizable to any mutant- or wild-type of worm regardless of speed and activity.\\


\subsection{Acquiring Video for Analysis}
A critical first step in analyzing and quantifying worm behaviors involves acquiring video. In order to capture subtle differences in individual animal behavior, it is of high importance to capture worm movement at appropriate time and imaging resolution under imaging conditions favoring accurate extraction of intermediate representations of the worm's per-frame posture. \\

A high and accurate frame rate will provide time scales suitable for motion analysis. It will also provide more image data from which to extract features, allowing data scientists to throw out video frames for which segmentation and skeletionizing is ineffective, in which the image has become corrupt, or the nematode has been blurred by the motion of the camera. Traditionally challenging postures to segment or skeletonize are looped or coiled. The practice of throwing out these frames is slightly misguided, however, as often the frames being thrown out are those of high importance for locomotory analysis.\\

In order to provide an advantage to the segmentation process, optimizing the image quality is important. This can be accomplished by providing even and uniform illumination at time of capture, facilitating the process of finding intensity thresholds that best separate a worm from its agar background. In order to minimize unwanted image artifacts effecting the selection of only worm pixels during segmentation, it is recommended to ensure proper care in the pouring of the agar (substrate upon which the worm is crawling), and imaging the plate with few fingerprints on the dish (trivial, but important!) Also, the dish should be imaged with the agar portion of the dish facing up, allowing possible condensation observed over long recording periods to travel downwards, minimizing its impact on the image quality.\\

Currently, most trackers available are written in MATLAB/C++ and require the Image Analysis Toolbox in order to acquire frames from a camera. Many require expensive hardware, making \textit{C. elegans} motorized tracking an expensive and exclusive endeavour.\\ 


\subsection{Quantifying Worm Behavior through Video Analysis}
\label{ss:quant}
Though slightly outside the scope of our current investigation, it is important to note some of the standard methods for extracting features. Given our position to control the quality of the images to be provided to the feature extraction and analysis routines, some design decisions at our current stage may impact the effectiveness of further study.\\

A popular approach in the field is to generate decompositional features from the videos acquired \cite{feng2004}. In general, four ``intermediate'' representations are calculated using the image processing sequence from Figure~\ref{fig:stdIP}.\\

\begin{figure}
\begin{tikzpicture}
%[node distance = 1cm, auto,font=\footnotesize,
% STYLES
%every node/.style={node distance=3cm},
% The force style is used to draw the forces' name
[force/.style={rectangle, draw, fill=black!10, inner sep=5pt, text width=2.5cm, text badly centered, minimum height=1.2cm, font=\bfseries\footnotesize\sffamily}] 

% Draw forces
\node [force] (vid) {Video Frame};
\node [force, right=1cm of vid] (seg){Segmentation};
\node [force, right=1cm of seg] (skel){Skeletonization (Binarization)};
\node [force, right=1cm of skel] (ht){Head Tail Identification};
\node [force, right=1cm of ht] (skelpt){Skeleton Sampling};


% Draw the links between forces
\path[->,thick] 
(vid) edge (seg)
(seg) edge (skel)
(skel) edge (ht)
(ht) edge (skelpt);

\end{tikzpicture} 
\caption{Standard image processing sequence for intermediate representations}
\label{fig:stdIP}
\end{figure} 

The original gray scale image is only used to provide information about the animal's \textit{translucency} (for head/tail identication, mainly). From the gray scale image, a binary image is generated by applying a threshold segmentation. From this image \textit{size} and \textit{shape} features are calculation (as \textbf{morphology features}). From the binary image, the centroid is found as a representation of the worm's \textit{position} extrapolated to \textbf{trajectory features} across multiple frames (such as \textit{direction, displacement, velocity and acceleration}). From the segmentation, a medial axis is determined using skeletonization techniques. This is a complex problem when applied to looped or curled postures in which occlusion might occur \cite{huang2006}. This skeleton is then downsampled to a number of representative points (anywhere between 13 \cite{} and 47 \cite{}) ordered from head to tail. The head and tail distinction can be automatically attempted using the presence of intensity, curvature or width profile differences between a nematode's head and tail, though this task is not inherently trivial.\\

Features extracted from these intermediate representations have been widely used by the Schafer research lab for phenotype analysis as inputs to: phenotype classification using decision trees \cite{baek2002, geng2004} or phenotypic clustering \cite{geng2003}. Also, these features can be used to annotate video frames with some commonly described behaviors such as crawling and turns (reversals, shallow turns, omega loops, and gamma loops.)\\

%\cite{huang
Other approaches to extracting features involve tracking only the worm's centroid frame-to-frame to get information about the worm's complete path (or trail). This path's curvature can be modeled as piece-wise harmonic functions \cite{padmanabhan2012} or using differential tangent angles and arc lengths \cite{kim2011}. \\

Finally, \cite{stephens2008} discovered that any worm \textit{posture} can be represented using four basic shapes (or eigenworms). Both eigenworm and trail analyses model posture over time. An advantage to using eigenworms over trail analysis is these basic shapes are learned from all frames (so each frame contributes), but any individual frame can be modelled using this approach (frame-centric approach). Trail analysis models postures across multiple frames without frame-to-frame distinction. In \cite{stephens2010}, the eigenworm model is coupled with center-of-mass trajectory analysis. \\

Using unsupervised learning techniques, \cite{brown2013} uses eigenworm representations of the worm \textbf{postures} developed in \cite{stephens2008} to identify and discover behavioral motifs (or patterns) to use in clustering phenotypes. I project we will possibly build on this approach, focusing on a smaller, more focused subset of candidate mutants of interest to Dr. Kim, instead of a wide variety of mutants as profiled in \cite{yemini2013} in order to find model posture-similarity between two individual worms. \\ 

In terms of observing worms off-food, it has been attempted by \cite{kim2011} (details to follow) and \cite{hoshi2006} for 70 min for 3 mutant types in a 15cm assay at 3 fps. (We can do better).\\

Ultimately, given our goal of determining similarity between two worms based on their locomotory behavior, once we complete the image acquisition software, we will investigate the utility of many of the features described, including: \textbf{morphology}, \textbf{posture},  and \textbf{trajectory} features. \\
\end{document}
